{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a5ef22-e783-4110-b8a0-0aeaa426898d",
   "metadata": {},
   "source": [
    "# Awkward Array x NVIDIA\n",
    "Awkward Array provides an API to perform calculations using NVIDIA GPUs if available. This provides an interface familiar to Awkward users without needing any new knowledge of CUDA programming. Below, I will show how simple it is to leverage GPUs as accelerators with awkward.\n",
    "\n",
    "First, let's create an array of data on both the cpu and GPU by specifying the requested 'backend'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d8b51-e9d9-4511-958d-f3f518c91508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "data = np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
    "array_CPU = ak.Array(data, backend = \"cpu\")\n",
    "array_GPU = ak.Array(data, backend = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841c80d-a80b-49bc-8114-8e2c0f411aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb288178-8c05-4951-9e5f-5587ce81b0d2",
   "metadata": {},
   "source": [
    "Let's compare the performance between the backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b367397-caef-482e-9f9f-773daf9781b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# CPU\n",
    "array_CPU**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d83f7c-2397-4258-9509-bc34c13d9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# GPU\n",
    "array_GPU**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d124468-7da1-4a6f-9049-9adf674c6eb3",
   "metadata": {},
   "source": [
    "But wait! Here we see that using the GPU is a fair bit slower. GPUs have high throughput, but they also have high latency. It takes time for the CPU to send instructions to the GPU, and copying the result back to the host (CPU) is an expensive operation. GPUs realize performance benefits when the computation time far exceeds the latency overhead. Let's compare again but with much more data (~4GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f1ee2-d988-4006-868c-08c0dfd7332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.int32\n",
    "shape = (500_000_000)\n",
    "data = np.random.default_rng().integers(low=0,high=10,size = shape)\n",
    "array_CPU = ak.Array(data, backend = \"cpu\")\n",
    "array_GPU = ak.Array(data, backend = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e380c-47fb-4e1c-bd5c-b4e01e4799de",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175a060-1ac1-4b88-ae76-5f4bd5f8a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = array_CPU**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827e2f4-7a4f-4f2b-84f6-3e828d940a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = array_GPU**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a0262-680a-4272-b449-f59d5e6aaa90",
   "metadata": {},
   "source": [
    "# Cupy\n",
    "\n",
    "`Cupy` is a library which functions as an extension of `numpy` but for arrays stored on CUDA capable GPUs. Many of the numpy functions are implemented for `cupy`, and `cupy` provides an API which gives access to certain cuda functionalities (device synching, cuda streams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d577bb-b558-4b38-af46-efb24ce77890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "shape = (1000,1000)\n",
    "data = np.random.default_rng().integers(low=0,high=100,size = shape)\n",
    "data_cupy = cp.array(data)\n",
    "data_cpu = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa354b-2ec4-42ea-adb0-2a61b1aebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data_cupy))\n",
    "print(data_cupy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb6961-217d-4d11-ba63-33a7147e3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "result = np.matmul(data_cpu, data_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96da1d0-cd71-4db1-aa10-fa9a06b578b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "result = cp.matmul(data_cupy, data_cupy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb1f8b-749f-4366-b6e8-75f743e43923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-kvikio-cuda12.5-py3.11]",
   "language": "python",
   "name": "conda-env-.conda-kvikio-cuda12.5-py3.11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
